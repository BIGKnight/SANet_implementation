{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzn/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbb2f0b0561b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mRMSE_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSE_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0msummary_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mMAE_\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mMSE_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                         \u001b[0mvalidate_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mMAE_scaler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMAE_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE_scaler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMSE_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         \u001b[0mvalidate_summary_writter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./summary/validate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# %load /home/zzn/PycharmProjects/SANet_implementation/main.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import SANet_model\n",
    "result_output = open(\"/home/zzn/SANet_implementation-master/result_B_12.13.txt\", \"w\")\n",
    "image_train_path = \"/home/zzn/part_B_final/train_data/images_train.npy\"\n",
    "gt_train_path = \"/home/zzn/part_B_final/train_data/gt_train.npy\"\n",
    "image_validate_path = \"/home/zzn/part_B_final/train_data/images_validate.npy\"\n",
    "gt_validate_path = \"/home/zzn/part_B_final/train_data/gt_validate.npy\"\n",
    "batch_size = 1\n",
    "epoch = 500\n",
    "loss_c_weight = 0.001\n",
    "MAE = 19970305\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_train = np.load(image_train_path)\n",
    "    gt_train = np.load(gt_train_path)\n",
    "    image_validate = np.load(image_validate_path)\n",
    "    gt_validate = np.load(gt_validate_path)\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"input\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, None, None, 1], name=\"label\")\n",
    "    estimated_density_map = SANet_model.scale_aggregation_network(x)\n",
    "    estimated_counting = tf.reduce_sum(estimated_density_map, reduction_indices=[1, 2, 3], name=\"crowd_counting\")\n",
    "    ground_truth_counting = tf.reduce_sum(y, reduction_indices=[1, 2, 3])\n",
    "    ground_truth_counting = tf.cast(ground_truth_counting, tf.float32)\n",
    "\n",
    "    loss_e = tf.losses.mean_squared_error(y, predictions=estimated_density_map)\n",
    "    loss_c = utils.structural_similarity_index_metric(estimated_density_map, y)\n",
    "    loss = tf.add(loss_e, tf.multiply(loss_c_weight, loss_c))\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    # the eval+metric_ops get the MAE and MSE of one batch\n",
    "    eval_metric_ops = {\n",
    "        'MAE': tf.reduce_mean(tf.abs(tf.subtract(estimated_counting, ground_truth_counting)), axis=0, name=\"MAE\"),\n",
    "        'MSE': tf.reduce_mean(tf.square(tf.subtract(ground_truth_counting, estimated_counting)), axis=0, name=\"MSE\")\n",
    "    }\n",
    "   \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        image_train_num = len(image_train)\n",
    "        step = 0\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            shuffle_batch = np.random.permutation(image_train_num // batch_size)\n",
    "            for j in range(image_train_num // batch_size):\n",
    "                # train\n",
    "                start = (shuffle_batch[j] * batch_size) % image_train_num\n",
    "                end = min(start + batch_size, image_train_num)\n",
    "                sess.run(train_op, feed_dict={x: image_train[start:end], y: gt_train[start:end]})\n",
    "                step = step + 1\n",
    "\n",
    "                # validate\n",
    "                if step % 500 == 0:\n",
    "                    loss_ = []\n",
    "                    MAE_ = []\n",
    "                    MSE_ = []\n",
    "                    for k in range(len(image_validate // batch_size)):\n",
    "                        loss_eval, metric_eval = sess.run([loss, eval_metric_ops], feed_dict={x: image_validate[k:k+batch_size], y: gt_validate[k:k+batch_size]})\n",
    "                        loss_.append(loss_eval)\n",
    "                        MAE_.append(metric_eval['MAE'])\n",
    "                        MSE_.append(metric_eval['MSE'])\n",
    "                        \n",
    "                    # add summary of MAE and RMAE\n",
    "                    MAE_ = np.squeeze(MAE_)\n",
    "                    MSE_ = np.squeeze(MSE_)\n",
    "                    MAE_scaler = tf.placeholder(tf.float32, [None], name='MAE_scaler')\n",
    "                    MSE_scaler = tf.placeholder(tf.float32, [None], name='MSE_scaler')\n",
    "                    MAE_summary = tf.reduce_mean(MAE_scaler, axis=0)\n",
    "                    RMSE_summary = tf.sqrt(tf.reduce_mean(MSE_scaler, axis=0))\n",
    "                    summary_merged = tf.summary.merge_all()\n",
    "                    if len(MAE_) and len(MSE_):\n",
    "                        validate_summary = sess.run(summary_merged, feed_dict={MAE_scaler: MAE_, MSE_scaler: MSE_})\n",
    "                        validate_summary_writter = tf.summary.FileWriter('./summary/validate', sess.graph)\n",
    "                        validate_summary_writter.add_summary(validate_summary, step)\n",
    "                    \n",
    "                    # calculate the validate loss, validate MAE and validate RMSE\n",
    "                    validate_loss = np.mean(loss_)\n",
    "                    validate_MAE = np.mean(MAE_)\n",
    "                    validate_RMSE = np.sqrt(np.mean(MSE_))\n",
    "                    \n",
    "                    # show one of the validate samples\n",
    "                    figure, (origin, density_gt, pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "                    origin.imshow(image_validate[1])\n",
    "                    origin.set_title('Origin Image')\n",
    "                    density_gt.imshow(np.squeeze(gt_validate[1]), cmap=plt.cm.jet)\n",
    "                    density_gt.set_title('ground_truth')\n",
    "                    predict_den, gt_counts, pred_counts = sess.run([estimated_density_map, ground_truth_counting, estimated_counting], feed_dict={x: image_validate[1:2], y: gt_validate[1:2]})\n",
    "                    predict_den = np.squeeze(predict_den)\n",
    "                    pred.imshow(predict_den, cmap = plt.cm.jet)\n",
    "                    plt.suptitle(\"one sample from the validate\")\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # show the validate MAE and MSE values on stdout\n",
    "                    gt_counts = np.squeeze(gt_counts)\n",
    "                    pred_counts = np.squeeze(pred_counts)\n",
    "                    sys.stdout.write('The gt counts of the above sample:{}, and the pred counts:{}\\n'.format(gt_counts, pred_counts))\n",
    "                    sys.stdout.write('In step {}, epoch {}, with loss {}, MAE = {}, MSE = {}\\n'.format(step, i + 1, validate_loss, validate_MAE, validate_RMSE))            \n",
    "                    sys.stdout.flush()\n",
    "                    result_output.write(str(validate_loss) + \"      \" + \"MAE: \" + str(validate_MAE) + \" MSE: \" + str(validate_RMSE) + \"\\r\\n\")\n",
    "                    \n",
    "                    # save model\n",
    "                    if MAE > validate_MAE:\n",
    "                        MAE = validate_MAE\n",
    "                        saver.save(sess, './checkpoint_dir/MyModel_1')\n",
    "result_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
